{
  "cells": [
    {
      "metadata": {
        "_uuid": "f256a12e99d2f8358fba966abe2b42e18e05bca8"
      },
      "cell_type": "markdown",
      "source": "# Introduction\nIn this kernel I have played with the SVM hyperparameters using Grid Search to gain better accuracy on this problem. SVM generally tries to separate classes by constructing hyperplanes between them. These hyperplanes are constructed such that some chosen nearest points to the boundary/hyperplane in separate classes are as far as possible from the boundary/hyperplane. This provides for more possibility to correctly classify new data. The distance between chosen point and boundary is called margin and SVM objective is to maximize margin for the number of chosen points using hyperparameters."
    },
    {
      "metadata": {
        "_uuid": "52bd734d04337da135c6baf7ffb148e62ae356a5"
      },
      "cell_type": "markdown",
      "source": "## Importing Libraries\nUsed scikit-learn's SVM for classification"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import svm\nfrom sklearn.model_selection import train_test_split,StratifiedKFold\nfrom sklearn.grid_search import GridSearchCV\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncolor = sns.color_palette()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "61e3b90456cc2127b1b73664750c45deffaccdfa"
      },
      "cell_type": "markdown",
      "source": "### Loading Train and Test data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e790c494cfe8e48ebf4e6a119abc8bfadd039f50",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_train = pd.read_csv('../input/train.csv',nrows=5000,skiprows = range(1,2000))\ndf_train.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_test = pd.read_csv('../input/test.csv')\ndf_test.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f26a213a05f07b667489631c0ef12c4bacced913",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "df867aba6a1182c4181d189519cd31152c17cdcb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_test.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "18fc007d0a6a3a9b9da8be6c9beade0d0948f0d7"
      },
      "cell_type": "markdown",
      "source": "### Distribution of classes in Training Data\nAs per the bar chart, we can conclude that the training data has balanced classes and adequately represent the population of each class."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dfb514e6b7184017dba7f31cf30fe0bf37b682df",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "arr = df_train.label.value_counts()\nplt.bar(arr.index,arr.values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e9bc44c12b12118a9a57cb3c31e1cad94181085d"
      },
      "cell_type": "code",
      "source": "y = df_train['label']\ndf_train = df_train.drop('label',axis=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd703ed079df6f627b9fb597bd54c6a31e611469",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df_train.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ce03e82fb96fe62d8bb210827dca531ef8a79d60",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "725032c9d2b1c43669450a796fc816f6bae4a252"
      },
      "cell_type": "markdown",
      "source": "## Using Grid Search for parameter tuning\n#### About Important Parameters \n1.  The most important parameter is the kernel function, it controls the type of boundary to be constructed to separate classes. There are four types ( rbf, poly, linear, sigmoid ) of function but most widely used are - \n          \"rbf\" - radial basis function which maps data to higher dimension to construct a hyperplane to divide classes.\n          \"linear\" - creates a linear boundary to separate classes.\n          \n2.  C is the cost of misclassification. In other words it is trade-off between classification of training example and smooth decision boundary. C decides proportion of support vector/training examples to be chosen to construct the boundary. Larger the C - higher the variance and vice-versa as decision boundary is trying to maximise the margin for large number of points in space so its going to overfit training data. \n\n3.  \"gamma\" tells how far the influence of single training data is to be taken to construct the boundary. If gamma is large then we are giving high weight to near points and less to far away points leading to a high bias. On the other hand if gamma is small the we assign high weights to far away chosen points and less to nearby points thus causing high variance as data is boundary is trying to fit based on far away pata more for each class.\n\nNote: Values of gamma and C are highly dependent on dataset provided."
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "c01862cd17f2f6fe37cc68bf2cbcbb777b5cdf7a"
      },
      "cell_type": "code",
      "source": "params = [\n  {'C': [1, 5, 7, 10], 'random_state': [ 42, 179 ], 'kernel': ['linear']},\n  {'C': [1, 5, 7, 10], 'random_state':[ 42, 179], 'gamma': [5.0, 2.0, 1.0, 0.1], 'kernel': ['rbf']}\n]   \n#  {'C': [0.1, 0.5, 1, 5, 7, 10,], 'random_state':[ 42, 179], 'gamma': [1.0, 0.1, 0.01, 0.025, 0.001], 'degree':[2,3,4], 'kernel': ['poly']}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e72f25711fb5f310febfccf890c5f8ce8e62b604"
      },
      "cell_type": "markdown",
      "source": "### Declaring Grid Search Cross Validation"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "6c37f086a17401d8437a3e5e53c2073ff85bbb6e"
      },
      "cell_type": "code",
      "source": "gs_svm = GridSearchCV(estimator=svm.SVC(), param_grid=params, n_jobs=4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d05ae06ddb263a2e3b9c23e3efafbd5d3689a102"
      },
      "cell_type": "markdown",
      "source": "### Training over un-preprocessed Data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ebe73b687ee368cb4707994e7b8863f8551f0de",
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# X_train, X_valid, y_train, y_valid = train_test_split(df_train, y, test_size = 0.3, random_state = 42)\n# print(X_train.shape)\n# print(X_valid.shape)\n# print(y_train.shape)\n# print(y_valid.shape)\n# gs_svm.fit(X_train, y_train) \n# print(gs_svm.best_params_) \n# print(gs_svm.best_score_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2b51655471373f6954395ecee42303c33050abba"
      },
      "cell_type": "markdown",
      "source": "### Pre-processing Data\nData with positive pixel value are assigned 1"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "e3e8f1567a321b0125510081e6ed624ce59a034a"
      },
      "cell_type": "code",
      "source": "# #  Scaling the pixel values as SVM is not scale invariant\n# new_df_train = df_train.copy()\n# new_df_train[new_df_train>0] = 1\n# new_df_test = df_test.copy()\n# new_df_test[new_df_test>0] = 1\nnew_df_train = df_train.copy()\nnew_df_test = df_test.copy()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "88bb25d8d82f4e40b83eba733b51d8f25ed7ecbb"
      },
      "cell_type": "code",
      "source": "#X_train, X_valid, y_train, y_valid = train_test_split(new_df_train, y, test_size = 0.3, random_state = 42)\n# print(X_train.shape)\n# print(X_valid.shape)\n# print(y_train.shape)\n# print(y_valid.shape)\n# gs_svm.fit(X_train, y_train) \n# print(gs_svm.best_params_) \n# print(gs_svm.best_score_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45093ca9e8117f19893d6b1e75b290353e55c58d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# kfold = StratifiedKFold(n_splits=3,random_state=42)\n# for train_idx,valid_idx in kfold.split(new_df_train,y):\n#     X_train = new_df_train.iloc[train_idx]\n#     y_train = y.iloc[train_idx]\n#     X_valid = new_df_train.iloc[valid_idx]\n#     y_valid = y.iloc[valid_idx]\n#     gs_svm.fit(X_train, y_train)\n#     print(gs_svm.score(X_valid,y_valid))\n#     print(gs_svm.best_params_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "7e9795904320b239789816138cdfe64e5e7612c7"
      },
      "cell_type": "code",
      "source": "# df_test[df_test>0] = 1\n# y_predict = gs_svm.predict(df_test)\n# gs_svm.fit(X_train, y_train)  \n# print(gs_svm.best_score_)\n# print(gs_svm.best_param_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "36fc5bd54a7413c63271fb2b855acbb1cb637a61"
      },
      "cell_type": "markdown",
      "source": "### Pre-processing using PCA\nPCA( Principal component Analysis ) is a method of constructiong new characteristics such that old characteristics can be recovered. It is a better approximate of higher dimension data in lower dimension. By dimension I mean features. In this correlated features/dimensions are replaced with a linear combination or any function of these features. PCA looks for properties that show as much variation as possible. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "98c5dc4a4e878c50b77bd9254eb142677ccc0679",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pca_model = PCA(n_components=40)\nnew_df_train = pd.DataFrame(pca_model.fit_transform(new_df_train))\nnew_df_test = pd.DataFrame(pca_model.transform(new_df_test))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "088671d3134c68c8e071175d6bb78c3e124042e7"
      },
      "cell_type": "code",
      "source": "#X_train, X_valid, y_train, y_valid = train_test_split(new_df_train, y, test_size = 0.3, random_state = 42)\n# print(X_train.shape)\n# print(X_valid.shape)\n# print(y_train.shape)\n# print(y_valid.shape)\n# gs_svm.fit(X_train, y_train)  \n# print(gs_svm.best_score_)\n# print(gs_svm.best_param_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6d158b69376dbd8b9b403e4faf8ff3a3ce305aa5",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "kfold = StratifiedKFold(n_splits=3,random_state=42)\nfor train_idx,valid_idx in kfold.split(new_df_train,y):\n    X_train = new_df_train.iloc[train_idx]\n    y_train = y.iloc[train_idx]\n    X_valid = new_df_train.iloc[valid_idx]\n    y_valid = y.iloc[valid_idx]\n    gs_svm.fit(X_train, y_train)\n    print(gs_svm.score(X_valid,y_valid))\n    print(gs_svm.best_params_)\ny_predict = gs_svm.predict(new_df_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad60063572cdb3f69570fc7e4d74973821a71dc0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "y_predict.shape",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dff550ac85d9855f7d07922c94faf7ddce1d3d6e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "sample_csv = pd.read_csv('../input/sample_submission.csv')\nsample_csv['Label'] = y_predict\nsample_csv.to_csv(\"output.csv\", index=False, header=True)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}