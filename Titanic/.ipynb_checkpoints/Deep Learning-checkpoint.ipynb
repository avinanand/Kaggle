{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import strftime,gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Altaireon\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense,Activation,Dropout\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.activations import elu,relu,sigmoid,tanh\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l1,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 700\n",
    "verbose = 1\n",
    "classes = 2\n",
    "optimiser = Adam()\n",
    "validation_split = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(relu))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(relu))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(250))\n",
    "model.add(Activation(relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(relu))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation(relu))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(classes))\n",
    "model.add(Activation(sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Dataset/feature_engg_train.csv')\n",
    "df_gs = pd.read_csv('Dataset/gender_submission.csv')\n",
    "df_test = pd.read_csv('Dataset/feature_engg_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>A5</th>\n",
       "      <th>A4</th>\n",
       "      <th>Other</th>\n",
       "      <th>C</th>\n",
       "      <th>CA</th>\n",
       "      <th>FC</th>\n",
       "      <th>LINE</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_H</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Male</th>\n",
       "      <th>Female</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Parch  Fare   A5   A4  Other    C   CA   FC  LINE    ...     Cabin_H  \\\n",
       "0    1      0     0  1.0  0.0    0.0  0.0  0.0  0.0   0.0    ...           0   \n",
       "1    2      0     3  0.0  0.0    0.0  0.0  0.0  0.0   0.0    ...           0   \n",
       "2    1      0     1  0.0  0.0    0.0  0.0  0.0  0.0   0.0    ...           0   \n",
       "3    2      0     3  0.0  0.0    0.0  0.0  0.0  0.0   0.0    ...           0   \n",
       "4    2      0     1  0.0  0.0    0.0  0.0  0.0  0.0   0.0    ...           0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Male  Female  Pclass_1  Pclass_2  \\\n",
       "0         0.0         0.0         1.0   0.0     1.0       0.0       0.0   \n",
       "1         1.0         0.0         0.0   1.0     0.0       1.0       0.0   \n",
       "2         0.0         0.0         1.0   1.0     0.0       0.0       0.0   \n",
       "3         0.0         0.0         1.0   1.0     0.0       1.0       0.0   \n",
       "4         0.0         0.0         1.0   0.0     1.0       0.0       0.0   \n",
       "\n",
       "   Pclass_3  Survived  \n",
       "0       1.0         0  \n",
       "1       0.0         1  \n",
       "2       1.0         1  \n",
       "3       0.0         1  \n",
       "4       1.0         0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Parch', 'Fare', 'A5', 'A4', 'Other', 'C', 'CA', 'FC', 'LINE',\n",
       "       'PP', 'PC', 'SC', 'SO', 'Paris', 'AH', 'O2', 'OQ', 'WC', 'WE', 'Title',\n",
       "       'Name_length', 'FamilySize', 'Cabin_null', 'Cabin_A', 'Cabin_B',\n",
       "       'Cabin_C', 'Cabin_D', 'Cabin_E', 'Cabin_F', 'Cabin_G', 'Cabin_H',\n",
       "       'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Male', 'Female', 'Pclass_1',\n",
       "       'Pclass_2', 'Pclass_3', 'Survived'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['Survived']\n",
    "df_train.drop('Survived',axis=1,inplace=True)\n",
    "# df_train = df_train[['Age', 'Parch', 'Fare', 'Title', 'Name_length', 'FamilySize',\n",
    "#        'Cabin_null', 'Cabin_B', 'Embarked_C', 'Embarked_S', 'Male', 'Female',\n",
    "#        'Pclass_1', 'Pclass_2', 'Pclass_3']]\n",
    "# df_test = df_test[['Age', 'Parch', 'Fare', 'Title', 'Name_length', 'FamilySize',\n",
    "#        'Cabin_null', 'Cabin_B', 'Embarked_C', 'Embarked_S', 'Male', 'Female',\n",
    "#        'Pclass_1', 'Pclass_2', 'Pclass_3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimiser,loss='binary_crossentropy',metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Altaireon\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/500\n",
      "623/623 [==============================] - 1s 2ms/step - loss: 0.9333 - binary_accuracy: 0.4920 - val_loss: 0.7147 - val_binary_accuracy: 0.3899\n",
      "Epoch 2/500\n",
      "623/623 [==============================] - 0s 95us/step - loss: 0.7802 - binary_accuracy: 0.4518 - val_loss: 0.7115 - val_binary_accuracy: 0.5000\n",
      "Epoch 3/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.7715 - binary_accuracy: 0.4944 - val_loss: 0.6977 - val_binary_accuracy: 0.5000\n",
      "Epoch 4/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.7440 - binary_accuracy: 0.5297 - val_loss: 0.6818 - val_binary_accuracy: 0.6493\n",
      "Epoch 5/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.7256 - binary_accuracy: 0.5618 - val_loss: 0.6763 - val_binary_accuracy: 0.6418\n",
      "Epoch 6/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.7378 - binary_accuracy: 0.5602 - val_loss: 0.6787 - val_binary_accuracy: 0.6418\n",
      "Epoch 7/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.7154 - binary_accuracy: 0.5859 - val_loss: 0.6807 - val_binary_accuracy: 0.6418\n",
      "Epoch 8/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.7079 - binary_accuracy: 0.5859 - val_loss: 0.6806 - val_binary_accuracy: 0.6549\n",
      "Epoch 9/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.7045 - binary_accuracy: 0.5722 - val_loss: 0.6810 - val_binary_accuracy: 0.6660\n",
      "Epoch 10/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.6858 - binary_accuracy: 0.5778 - val_loss: 0.6838 - val_binary_accuracy: 0.6754\n",
      "Epoch 11/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.6956 - binary_accuracy: 0.5506 - val_loss: 0.6883 - val_binary_accuracy: 0.5485\n",
      "Epoch 12/500\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.6865 - binary_accuracy: 0.5682 - val_loss: 0.6922 - val_binary_accuracy: 0.5112\n",
      "Epoch 13/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.6965 - binary_accuracy: 0.5297 - val_loss: 0.6942 - val_binary_accuracy: 0.5056\n",
      "Epoch 14/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.6888 - binary_accuracy: 0.5490 - val_loss: 0.6945 - val_binary_accuracy: 0.5112\n",
      "Epoch 15/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.6896 - binary_accuracy: 0.5329 - val_loss: 0.6934 - val_binary_accuracy: 0.5243\n",
      "Epoch 16/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.6930 - binary_accuracy: 0.5273 - val_loss: 0.6913 - val_binary_accuracy: 0.5709\n",
      "Epoch 17/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.6828 - binary_accuracy: 0.5682 - val_loss: 0.6884 - val_binary_accuracy: 0.6940\n",
      "Epoch 18/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.6736 - binary_accuracy: 0.5714 - val_loss: 0.6858 - val_binary_accuracy: 0.7295\n",
      "Epoch 19/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.6756 - binary_accuracy: 0.5803 - val_loss: 0.6833 - val_binary_accuracy: 0.7015\n",
      "Epoch 20/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.6715 - binary_accuracy: 0.6100 - val_loss: 0.6807 - val_binary_accuracy: 0.6996\n",
      "Epoch 21/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.6707 - binary_accuracy: 0.6156 - val_loss: 0.6784 - val_binary_accuracy: 0.6959\n",
      "Epoch 22/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.6737 - binary_accuracy: 0.6035 - val_loss: 0.6758 - val_binary_accuracy: 0.6735\n",
      "Epoch 23/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.6686 - binary_accuracy: 0.6132 - val_loss: 0.6730 - val_binary_accuracy: 0.6530\n",
      "Epoch 24/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.6726 - binary_accuracy: 0.5963 - val_loss: 0.6703 - val_binary_accuracy: 0.6493\n",
      "Epoch 25/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.6636 - binary_accuracy: 0.6268 - val_loss: 0.6668 - val_binary_accuracy: 0.6493\n",
      "Epoch 26/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.6555 - binary_accuracy: 0.6204 - val_loss: 0.6630 - val_binary_accuracy: 0.6455\n",
      "Epoch 27/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.6546 - binary_accuracy: 0.6276 - val_loss: 0.6590 - val_binary_accuracy: 0.6530\n",
      "Epoch 28/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.6513 - binary_accuracy: 0.6380 - val_loss: 0.6552 - val_binary_accuracy: 0.7108\n",
      "Epoch 29/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.6509 - binary_accuracy: 0.6477 - val_loss: 0.6523 - val_binary_accuracy: 0.7463\n",
      "Epoch 30/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.6493 - binary_accuracy: 0.6340 - val_loss: 0.6496 - val_binary_accuracy: 0.7668\n",
      "Epoch 31/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.6455 - binary_accuracy: 0.6597 - val_loss: 0.6460 - val_binary_accuracy: 0.7743\n",
      "Epoch 32/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.6366 - binary_accuracy: 0.6557 - val_loss: 0.6389 - val_binary_accuracy: 0.7799\n",
      "Epoch 33/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.6340 - binary_accuracy: 0.6581 - val_loss: 0.6290 - val_binary_accuracy: 0.7761\n",
      "Epoch 34/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.6389 - binary_accuracy: 0.6421 - val_loss: 0.6185 - val_binary_accuracy: 0.7817\n",
      "Epoch 35/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.6221 - binary_accuracy: 0.6709 - val_loss: 0.6040 - val_binary_accuracy: 0.7780\n",
      "Epoch 36/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.6108 - binary_accuracy: 0.6974 - val_loss: 0.5888 - val_binary_accuracy: 0.7743\n",
      "Epoch 37/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.6016 - binary_accuracy: 0.6894 - val_loss: 0.5747 - val_binary_accuracy: 0.7705\n",
      "Epoch 38/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.6053 - binary_accuracy: 0.6830 - val_loss: 0.5647 - val_binary_accuracy: 0.7743\n",
      "Epoch 39/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.6101 - binary_accuracy: 0.6766 - val_loss: 0.5589 - val_binary_accuracy: 0.7836\n",
      "Epoch 40/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.5857 - binary_accuracy: 0.6942 - val_loss: 0.5590 - val_binary_accuracy: 0.7929\n",
      "Epoch 41/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.5721 - binary_accuracy: 0.7111 - val_loss: 0.5577 - val_binary_accuracy: 0.7966\n",
      "Epoch 42/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.5782 - binary_accuracy: 0.7231 - val_loss: 0.5474 - val_binary_accuracy: 0.7985\n",
      "Epoch 43/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.5672 - binary_accuracy: 0.7271 - val_loss: 0.5275 - val_binary_accuracy: 0.7948\n",
      "Epoch 44/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.5732 - binary_accuracy: 0.7207 - val_loss: 0.5195 - val_binary_accuracy: 0.7985\n",
      "Epoch 45/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.5487 - binary_accuracy: 0.7432 - val_loss: 0.5144 - val_binary_accuracy: 0.8041\n",
      "Epoch 46/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.5540 - binary_accuracy: 0.7327 - val_loss: 0.5186 - val_binary_accuracy: 0.8004\n",
      "Epoch 47/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.5392 - binary_accuracy: 0.7360 - val_loss: 0.5161 - val_binary_accuracy: 0.8022\n",
      "Epoch 48/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.5387 - binary_accuracy: 0.7400 - val_loss: 0.5093 - val_binary_accuracy: 0.8004\n",
      "Epoch 49/500\n",
      "623/623 [==============================] - 0s 84us/step - loss: 0.5431 - binary_accuracy: 0.7247 - val_loss: 0.5067 - val_binary_accuracy: 0.8041\n",
      "Epoch 50/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.5325 - binary_accuracy: 0.7352 - val_loss: 0.5074 - val_binary_accuracy: 0.8004\n",
      "Epoch 51/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.5038 - binary_accuracy: 0.7769 - val_loss: 0.4999 - val_binary_accuracy: 0.8078\n",
      "Epoch 52/500\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.5284 - binary_accuracy: 0.7568 - val_loss: 0.5033 - val_binary_accuracy: 0.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.5406 - binary_accuracy: 0.7287 - val_loss: 0.5026 - val_binary_accuracy: 0.8041\n",
      "Epoch 54/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.5156 - binary_accuracy: 0.7416 - val_loss: 0.4997 - val_binary_accuracy: 0.8078\n",
      "Epoch 55/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.5194 - binary_accuracy: 0.7504 - val_loss: 0.4972 - val_binary_accuracy: 0.8134\n",
      "Epoch 56/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.5342 - binary_accuracy: 0.7295 - val_loss: 0.4927 - val_binary_accuracy: 0.8041\n",
      "Epoch 57/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.5323 - binary_accuracy: 0.7496 - val_loss: 0.4933 - val_binary_accuracy: 0.8078\n",
      "Epoch 58/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.5152 - binary_accuracy: 0.7616 - val_loss: 0.4927 - val_binary_accuracy: 0.8097\n",
      "Epoch 59/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.4941 - binary_accuracy: 0.7777 - val_loss: 0.4903 - val_binary_accuracy: 0.8134\n",
      "Epoch 60/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4894 - binary_accuracy: 0.7841 - val_loss: 0.4861 - val_binary_accuracy: 0.8097\n",
      "Epoch 61/500\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.5021 - binary_accuracy: 0.7713 - val_loss: 0.4845 - val_binary_accuracy: 0.8134\n",
      "Epoch 62/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4868 - binary_accuracy: 0.7753 - val_loss: 0.4837 - val_binary_accuracy: 0.8116\n",
      "Epoch 63/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4969 - binary_accuracy: 0.7640 - val_loss: 0.4836 - val_binary_accuracy: 0.8097\n",
      "Epoch 64/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.4843 - binary_accuracy: 0.7833 - val_loss: 0.4847 - val_binary_accuracy: 0.8097\n",
      "Epoch 65/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.4786 - binary_accuracy: 0.7833 - val_loss: 0.4853 - val_binary_accuracy: 0.8134\n",
      "Epoch 66/500\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.4911 - binary_accuracy: 0.7737 - val_loss: 0.4866 - val_binary_accuracy: 0.8134\n",
      "Epoch 67/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.5021 - binary_accuracy: 0.7657 - val_loss: 0.4834 - val_binary_accuracy: 0.8097\n",
      "Epoch 68/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4808 - binary_accuracy: 0.7897 - val_loss: 0.4793 - val_binary_accuracy: 0.8153\n",
      "Epoch 69/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4770 - binary_accuracy: 0.7905 - val_loss: 0.4775 - val_binary_accuracy: 0.8134\n",
      "Epoch 70/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4885 - binary_accuracy: 0.7905 - val_loss: 0.4769 - val_binary_accuracy: 0.8116\n",
      "Epoch 71/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.4931 - binary_accuracy: 0.7905 - val_loss: 0.4757 - val_binary_accuracy: 0.8153\n",
      "Epoch 72/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4672 - binary_accuracy: 0.8018 - val_loss: 0.4782 - val_binary_accuracy: 0.8172\n",
      "Epoch 73/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.4851 - binary_accuracy: 0.7793 - val_loss: 0.4839 - val_binary_accuracy: 0.8153\n",
      "Epoch 74/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.4754 - binary_accuracy: 0.7881 - val_loss: 0.4832 - val_binary_accuracy: 0.8134\n",
      "Epoch 75/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.4795 - binary_accuracy: 0.7953 - val_loss: 0.4762 - val_binary_accuracy: 0.8190\n",
      "Epoch 76/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.4564 - binary_accuracy: 0.8034 - val_loss: 0.4723 - val_binary_accuracy: 0.8116\n",
      "Epoch 77/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4655 - binary_accuracy: 0.7921 - val_loss: 0.4729 - val_binary_accuracy: 0.7948\n",
      "Epoch 78/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.4618 - binary_accuracy: 0.8026 - val_loss: 0.4722 - val_binary_accuracy: 0.7948\n",
      "Epoch 79/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.4844 - binary_accuracy: 0.7865 - val_loss: 0.4709 - val_binary_accuracy: 0.8097\n",
      "Epoch 80/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4649 - binary_accuracy: 0.7905 - val_loss: 0.4729 - val_binary_accuracy: 0.8246\n",
      "Epoch 81/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4546 - binary_accuracy: 0.8098 - val_loss: 0.4741 - val_binary_accuracy: 0.8228\n",
      "Epoch 82/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.4722 - binary_accuracy: 0.7889 - val_loss: 0.4738 - val_binary_accuracy: 0.8246\n",
      "Epoch 83/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.4726 - binary_accuracy: 0.7865 - val_loss: 0.4712 - val_binary_accuracy: 0.8209\n",
      "Epoch 84/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.4721 - binary_accuracy: 0.7873 - val_loss: 0.4696 - val_binary_accuracy: 0.8172\n",
      "Epoch 85/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.4693 - binary_accuracy: 0.8002 - val_loss: 0.4688 - val_binary_accuracy: 0.8172\n",
      "Epoch 86/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.4585 - binary_accuracy: 0.7953 - val_loss: 0.4684 - val_binary_accuracy: 0.8134\n",
      "Epoch 87/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.4601 - binary_accuracy: 0.8026 - val_loss: 0.4679 - val_binary_accuracy: 0.8060\n",
      "Epoch 88/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.4679 - binary_accuracy: 0.7929 - val_loss: 0.4678 - val_binary_accuracy: 0.8134\n",
      "Epoch 89/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.4708 - binary_accuracy: 0.8002 - val_loss: 0.4679 - val_binary_accuracy: 0.8172\n",
      "Epoch 90/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4605 - binary_accuracy: 0.8050 - val_loss: 0.4671 - val_binary_accuracy: 0.8153\n",
      "Epoch 91/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4577 - binary_accuracy: 0.8146 - val_loss: 0.4658 - val_binary_accuracy: 0.8153\n",
      "Epoch 92/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4559 - binary_accuracy: 0.8098 - val_loss: 0.4651 - val_binary_accuracy: 0.8153\n",
      "Epoch 93/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.4542 - binary_accuracy: 0.8066 - val_loss: 0.4643 - val_binary_accuracy: 0.8097\n",
      "Epoch 94/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4483 - binary_accuracy: 0.8178 - val_loss: 0.4632 - val_binary_accuracy: 0.8004\n",
      "Epoch 95/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.4578 - binary_accuracy: 0.8058 - val_loss: 0.4627 - val_binary_accuracy: 0.8041\n",
      "Epoch 96/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.4362 - binary_accuracy: 0.8146 - val_loss: 0.4624 - val_binary_accuracy: 0.8116\n",
      "Epoch 97/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.4449 - binary_accuracy: 0.8130 - val_loss: 0.4623 - val_binary_accuracy: 0.8153\n",
      "Epoch 98/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4504 - binary_accuracy: 0.8146 - val_loss: 0.4623 - val_binary_accuracy: 0.8172\n",
      "Epoch 99/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.4490 - binary_accuracy: 0.8130 - val_loss: 0.4621 - val_binary_accuracy: 0.8172\n",
      "Epoch 100/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4707 - binary_accuracy: 0.7986 - val_loss: 0.4614 - val_binary_accuracy: 0.8153\n",
      "Epoch 101/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4458 - binary_accuracy: 0.8170 - val_loss: 0.4599 - val_binary_accuracy: 0.8097\n",
      "Epoch 102/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.4431 - binary_accuracy: 0.8082 - val_loss: 0.4590 - val_binary_accuracy: 0.8097\n",
      "Epoch 103/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4644 - binary_accuracy: 0.7953 - val_loss: 0.4583 - val_binary_accuracy: 0.8004\n",
      "Epoch 104/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4476 - binary_accuracy: 0.8058 - val_loss: 0.4578 - val_binary_accuracy: 0.8004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4500 - binary_accuracy: 0.8138 - val_loss: 0.4575 - val_binary_accuracy: 0.8004\n",
      "Epoch 106/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.4455 - binary_accuracy: 0.8122 - val_loss: 0.4577 - val_binary_accuracy: 0.8041\n",
      "Epoch 107/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.4475 - binary_accuracy: 0.8034 - val_loss: 0.4578 - val_binary_accuracy: 0.8041\n",
      "Epoch 108/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.4380 - binary_accuracy: 0.8170 - val_loss: 0.4579 - val_binary_accuracy: 0.8060\n",
      "Epoch 109/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4525 - binary_accuracy: 0.8050 - val_loss: 0.4572 - val_binary_accuracy: 0.7985\n",
      "Epoch 110/500\n",
      "623/623 [==============================] - 0s 84us/step - loss: 0.4476 - binary_accuracy: 0.8146 - val_loss: 0.4570 - val_binary_accuracy: 0.7966\n",
      "Epoch 111/500\n",
      "623/623 [==============================] - 0s 92us/step - loss: 0.4580 - binary_accuracy: 0.8074 - val_loss: 0.4572 - val_binary_accuracy: 0.8041\n",
      "Epoch 112/500\n",
      "623/623 [==============================] - 0s 94us/step - loss: 0.4548 - binary_accuracy: 0.8066 - val_loss: 0.4585 - val_binary_accuracy: 0.8060\n",
      "Epoch 113/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4546 - binary_accuracy: 0.8170 - val_loss: 0.4594 - val_binary_accuracy: 0.8060\n",
      "Epoch 114/500\n",
      "623/623 [==============================] - 0s 88us/step - loss: 0.4572 - binary_accuracy: 0.8010 - val_loss: 0.4585 - val_binary_accuracy: 0.8060\n",
      "Epoch 115/500\n",
      "623/623 [==============================] - 0s 91us/step - loss: 0.4332 - binary_accuracy: 0.8138 - val_loss: 0.4578 - val_binary_accuracy: 0.8060\n",
      "Epoch 116/500\n",
      "623/623 [==============================] - 0s 81us/step - loss: 0.4432 - binary_accuracy: 0.8146 - val_loss: 0.4564 - val_binary_accuracy: 0.8041\n",
      "Epoch 117/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4407 - binary_accuracy: 0.8146 - val_loss: 0.4559 - val_binary_accuracy: 0.8004\n",
      "Epoch 118/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.4395 - binary_accuracy: 0.8162 - val_loss: 0.4556 - val_binary_accuracy: 0.7985\n",
      "Epoch 119/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.4393 - binary_accuracy: 0.8090 - val_loss: 0.4558 - val_binary_accuracy: 0.8078\n",
      "Epoch 120/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4415 - binary_accuracy: 0.8202 - val_loss: 0.4569 - val_binary_accuracy: 0.8060\n",
      "Epoch 121/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.4324 - binary_accuracy: 0.8202 - val_loss: 0.4585 - val_binary_accuracy: 0.8097\n",
      "Epoch 122/500\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.4277 - binary_accuracy: 0.8178 - val_loss: 0.4578 - val_binary_accuracy: 0.8078\n",
      "Epoch 123/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4449 - binary_accuracy: 0.8010 - val_loss: 0.4558 - val_binary_accuracy: 0.8097\n",
      "Epoch 124/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.4310 - binary_accuracy: 0.8170 - val_loss: 0.4548 - val_binary_accuracy: 0.8134\n",
      "Epoch 125/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4446 - binary_accuracy: 0.8202 - val_loss: 0.4545 - val_binary_accuracy: 0.8078\n",
      "Epoch 126/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.4651 - binary_accuracy: 0.8034 - val_loss: 0.4548 - val_binary_accuracy: 0.8078\n",
      "Epoch 127/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4307 - binary_accuracy: 0.8194 - val_loss: 0.4553 - val_binary_accuracy: 0.8116\n",
      "Epoch 128/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4469 - binary_accuracy: 0.8130 - val_loss: 0.4568 - val_binary_accuracy: 0.8097\n",
      "Epoch 129/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4533 - binary_accuracy: 0.8138 - val_loss: 0.4576 - val_binary_accuracy: 0.8097\n",
      "Epoch 130/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.4354 - binary_accuracy: 0.8162 - val_loss: 0.4570 - val_binary_accuracy: 0.8097\n",
      "Epoch 131/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.4321 - binary_accuracy: 0.8146 - val_loss: 0.4566 - val_binary_accuracy: 0.8097\n",
      "Epoch 132/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4414 - binary_accuracy: 0.8122 - val_loss: 0.4559 - val_binary_accuracy: 0.8041\n",
      "Epoch 133/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4261 - binary_accuracy: 0.8250 - val_loss: 0.4564 - val_binary_accuracy: 0.8041\n",
      "Epoch 134/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.4244 - binary_accuracy: 0.8234 - val_loss: 0.4563 - val_binary_accuracy: 0.8041\n",
      "Epoch 135/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.4282 - binary_accuracy: 0.8210 - val_loss: 0.4587 - val_binary_accuracy: 0.8078\n",
      "Epoch 136/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.4191 - binary_accuracy: 0.8218 - val_loss: 0.4602 - val_binary_accuracy: 0.8060\n",
      "Epoch 137/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.4267 - binary_accuracy: 0.8178 - val_loss: 0.4601 - val_binary_accuracy: 0.8078\n",
      "Epoch 138/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4185 - binary_accuracy: 0.8283 - val_loss: 0.4608 - val_binary_accuracy: 0.8134\n",
      "Epoch 139/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.4233 - binary_accuracy: 0.8210 - val_loss: 0.4587 - val_binary_accuracy: 0.8097\n",
      "Epoch 140/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4275 - binary_accuracy: 0.8291 - val_loss: 0.4563 - val_binary_accuracy: 0.8060\n",
      "Epoch 141/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4192 - binary_accuracy: 0.8250 - val_loss: 0.4553 - val_binary_accuracy: 0.8041\n",
      "Epoch 142/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.4262 - binary_accuracy: 0.8154 - val_loss: 0.4551 - val_binary_accuracy: 0.8041\n",
      "Epoch 143/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.4371 - binary_accuracy: 0.8114 - val_loss: 0.4556 - val_binary_accuracy: 0.8078\n",
      "Epoch 144/500\n",
      "623/623 [==============================] - 0s 53us/step - loss: 0.4309 - binary_accuracy: 0.8291 - val_loss: 0.4566 - val_binary_accuracy: 0.8060\n",
      "Epoch 145/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4237 - binary_accuracy: 0.8202 - val_loss: 0.4574 - val_binary_accuracy: 0.8097\n",
      "Epoch 146/500\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.4322 - binary_accuracy: 0.8178 - val_loss: 0.4577 - val_binary_accuracy: 0.8078\n",
      "Epoch 147/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.4315 - binary_accuracy: 0.8194 - val_loss: 0.4585 - val_binary_accuracy: 0.8060\n",
      "Epoch 148/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.4337 - binary_accuracy: 0.8074 - val_loss: 0.4587 - val_binary_accuracy: 0.8041\n",
      "Epoch 149/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.4236 - binary_accuracy: 0.8202 - val_loss: 0.4590 - val_binary_accuracy: 0.8041\n",
      "Epoch 150/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4313 - binary_accuracy: 0.8154 - val_loss: 0.4589 - val_binary_accuracy: 0.8060\n",
      "Epoch 151/500\n",
      "623/623 [==============================] - 0s 50us/step - loss: 0.4228 - binary_accuracy: 0.8170 - val_loss: 0.4584 - val_binary_accuracy: 0.8097\n",
      "Epoch 152/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4294 - binary_accuracy: 0.8138 - val_loss: 0.4572 - val_binary_accuracy: 0.8078\n",
      "Epoch 153/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4337 - binary_accuracy: 0.8218 - val_loss: 0.4561 - val_binary_accuracy: 0.8022\n",
      "Epoch 154/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4222 - binary_accuracy: 0.8363 - val_loss: 0.4559 - val_binary_accuracy: 0.8116\n",
      "Epoch 155/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.4236 - binary_accuracy: 0.8218 - val_loss: 0.4557 - val_binary_accuracy: 0.8116\n",
      "Epoch 156/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4067 - binary_accuracy: 0.8355 - val_loss: 0.4560 - val_binary_accuracy: 0.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4181 - binary_accuracy: 0.8258 - val_loss: 0.4553 - val_binary_accuracy: 0.8116\n",
      "Epoch 158/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4092 - binary_accuracy: 0.8355 - val_loss: 0.4545 - val_binary_accuracy: 0.8116\n",
      "Epoch 159/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4199 - binary_accuracy: 0.8299 - val_loss: 0.4545 - val_binary_accuracy: 0.8116\n",
      "Epoch 160/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.4308 - binary_accuracy: 0.8242 - val_loss: 0.4543 - val_binary_accuracy: 0.8060\n",
      "Epoch 161/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.4243 - binary_accuracy: 0.8218 - val_loss: 0.4544 - val_binary_accuracy: 0.8078\n",
      "Epoch 162/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4156 - binary_accuracy: 0.8266 - val_loss: 0.4553 - val_binary_accuracy: 0.8060\n",
      "Epoch 163/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.4110 - binary_accuracy: 0.8291 - val_loss: 0.4571 - val_binary_accuracy: 0.8097\n",
      "Epoch 164/500\n",
      "623/623 [==============================] - 0s 96us/step - loss: 0.4207 - binary_accuracy: 0.8162 - val_loss: 0.4593 - val_binary_accuracy: 0.8078\n",
      "Epoch 165/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.4276 - binary_accuracy: 0.8250 - val_loss: 0.4603 - val_binary_accuracy: 0.8078\n",
      "Epoch 166/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4038 - binary_accuracy: 0.8242 - val_loss: 0.4601 - val_binary_accuracy: 0.8078\n",
      "Epoch 167/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4212 - binary_accuracy: 0.8226 - val_loss: 0.4588 - val_binary_accuracy: 0.8097\n",
      "Epoch 168/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.4098 - binary_accuracy: 0.8283 - val_loss: 0.4575 - val_binary_accuracy: 0.8097\n",
      "Epoch 169/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4234 - binary_accuracy: 0.8291 - val_loss: 0.4566 - val_binary_accuracy: 0.8060\n",
      "Epoch 170/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4087 - binary_accuracy: 0.8355 - val_loss: 0.4566 - val_binary_accuracy: 0.8097\n",
      "Epoch 171/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4177 - binary_accuracy: 0.8339 - val_loss: 0.4581 - val_binary_accuracy: 0.8134\n",
      "Epoch 172/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.4153 - binary_accuracy: 0.8291 - val_loss: 0.4587 - val_binary_accuracy: 0.8153\n",
      "Epoch 173/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.4073 - binary_accuracy: 0.8323 - val_loss: 0.4583 - val_binary_accuracy: 0.8153\n",
      "Epoch 174/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4080 - binary_accuracy: 0.8250 - val_loss: 0.4567 - val_binary_accuracy: 0.8153\n",
      "Epoch 175/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4096 - binary_accuracy: 0.8363 - val_loss: 0.4552 - val_binary_accuracy: 0.8134\n",
      "Epoch 176/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4201 - binary_accuracy: 0.8066 - val_loss: 0.4544 - val_binary_accuracy: 0.8078\n",
      "Epoch 177/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3987 - binary_accuracy: 0.8154 - val_loss: 0.4547 - val_binary_accuracy: 0.8097\n",
      "Epoch 178/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.4131 - binary_accuracy: 0.8202 - val_loss: 0.4556 - val_binary_accuracy: 0.8097\n",
      "Epoch 179/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4066 - binary_accuracy: 0.8411 - val_loss: 0.4568 - val_binary_accuracy: 0.8116\n",
      "Epoch 180/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4057 - binary_accuracy: 0.8323 - val_loss: 0.4582 - val_binary_accuracy: 0.8134\n",
      "Epoch 181/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.4036 - binary_accuracy: 0.8283 - val_loss: 0.4596 - val_binary_accuracy: 0.8153\n",
      "Epoch 182/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3965 - binary_accuracy: 0.8274 - val_loss: 0.4591 - val_binary_accuracy: 0.8153\n",
      "Epoch 183/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4086 - binary_accuracy: 0.8315 - val_loss: 0.4580 - val_binary_accuracy: 0.8134\n",
      "Epoch 184/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3984 - binary_accuracy: 0.8339 - val_loss: 0.4571 - val_binary_accuracy: 0.8134\n",
      "Epoch 185/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4194 - binary_accuracy: 0.8202 - val_loss: 0.4564 - val_binary_accuracy: 0.8172\n",
      "Epoch 186/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4089 - binary_accuracy: 0.8387 - val_loss: 0.4568 - val_binary_accuracy: 0.8134\n",
      "Epoch 187/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.4143 - binary_accuracy: 0.8202 - val_loss: 0.4562 - val_binary_accuracy: 0.8134\n",
      "Epoch 188/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4037 - binary_accuracy: 0.8323 - val_loss: 0.4549 - val_binary_accuracy: 0.8190\n",
      "Epoch 189/500\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.3943 - binary_accuracy: 0.8499 - val_loss: 0.4546 - val_binary_accuracy: 0.8190\n",
      "Epoch 190/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.4039 - binary_accuracy: 0.8266 - val_loss: 0.4551 - val_binary_accuracy: 0.8190\n",
      "Epoch 191/500\n",
      "623/623 [==============================] - 0s 100us/step - loss: 0.3978 - binary_accuracy: 0.8371 - val_loss: 0.4558 - val_binary_accuracy: 0.8209\n",
      "Epoch 192/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4125 - binary_accuracy: 0.8154 - val_loss: 0.4574 - val_binary_accuracy: 0.8116\n",
      "Epoch 193/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.4158 - binary_accuracy: 0.8202 - val_loss: 0.4573 - val_binary_accuracy: 0.8172\n",
      "Epoch 194/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4095 - binary_accuracy: 0.8283 - val_loss: 0.4589 - val_binary_accuracy: 0.8134\n",
      "Epoch 195/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.4081 - binary_accuracy: 0.8283 - val_loss: 0.4598 - val_binary_accuracy: 0.8134\n",
      "Epoch 196/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.4092 - binary_accuracy: 0.8274 - val_loss: 0.4596 - val_binary_accuracy: 0.8116\n",
      "Epoch 197/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.4166 - binary_accuracy: 0.8250 - val_loss: 0.4597 - val_binary_accuracy: 0.8116\n",
      "Epoch 198/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.4014 - binary_accuracy: 0.8363 - val_loss: 0.4589 - val_binary_accuracy: 0.8116\n",
      "Epoch 199/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.4017 - binary_accuracy: 0.8315 - val_loss: 0.4576 - val_binary_accuracy: 0.8134\n",
      "Epoch 200/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.3982 - binary_accuracy: 0.8403 - val_loss: 0.4574 - val_binary_accuracy: 0.8116\n",
      "Epoch 201/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4083 - binary_accuracy: 0.8339 - val_loss: 0.4578 - val_binary_accuracy: 0.8097\n",
      "Epoch 202/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.4043 - binary_accuracy: 0.8339 - val_loss: 0.4578 - val_binary_accuracy: 0.8078\n",
      "Epoch 203/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.4134 - binary_accuracy: 0.8315 - val_loss: 0.4568 - val_binary_accuracy: 0.8097\n",
      "Epoch 204/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.3940 - binary_accuracy: 0.8475 - val_loss: 0.4565 - val_binary_accuracy: 0.8097\n",
      "Epoch 205/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3886 - binary_accuracy: 0.8435 - val_loss: 0.4570 - val_binary_accuracy: 0.8078\n",
      "Epoch 206/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3930 - binary_accuracy: 0.8395 - val_loss: 0.4575 - val_binary_accuracy: 0.8078\n",
      "Epoch 207/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3935 - binary_accuracy: 0.8274 - val_loss: 0.4576 - val_binary_accuracy: 0.8078\n",
      "Epoch 208/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.4019 - binary_accuracy: 0.8323 - val_loss: 0.4573 - val_binary_accuracy: 0.8097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.4269 - binary_accuracy: 0.8194 - val_loss: 0.4548 - val_binary_accuracy: 0.8153\n",
      "Epoch 210/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.3970 - binary_accuracy: 0.8114 - val_loss: 0.4537 - val_binary_accuracy: 0.8172\n",
      "Epoch 211/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.3993 - binary_accuracy: 0.8387 - val_loss: 0.4545 - val_binary_accuracy: 0.8172\n",
      "Epoch 212/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.4142 - binary_accuracy: 0.8331 - val_loss: 0.4560 - val_binary_accuracy: 0.8190\n",
      "Epoch 213/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.3885 - binary_accuracy: 0.8258 - val_loss: 0.4580 - val_binary_accuracy: 0.8172\n",
      "Epoch 214/500\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.3969 - binary_accuracy: 0.8291 - val_loss: 0.4599 - val_binary_accuracy: 0.8097\n",
      "Epoch 215/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.4018 - binary_accuracy: 0.8331 - val_loss: 0.4607 - val_binary_accuracy: 0.8078\n",
      "Epoch 216/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.4084 - binary_accuracy: 0.8315 - val_loss: 0.4604 - val_binary_accuracy: 0.8078\n",
      "Epoch 217/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3990 - binary_accuracy: 0.8299 - val_loss: 0.4576 - val_binary_accuracy: 0.8116\n",
      "Epoch 218/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.4008 - binary_accuracy: 0.8266 - val_loss: 0.4547 - val_binary_accuracy: 0.8153\n",
      "Epoch 219/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.3960 - binary_accuracy: 0.8331 - val_loss: 0.4534 - val_binary_accuracy: 0.8209\n",
      "Epoch 220/500\n",
      "623/623 [==============================] - 0s 103us/step - loss: 0.4096 - binary_accuracy: 0.8283 - val_loss: 0.4535 - val_binary_accuracy: 0.8172\n",
      "Epoch 221/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3885 - binary_accuracy: 0.8347 - val_loss: 0.4552 - val_binary_accuracy: 0.8097\n",
      "Epoch 222/500\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.3917 - binary_accuracy: 0.8258 - val_loss: 0.4580 - val_binary_accuracy: 0.8097\n",
      "Epoch 223/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3997 - binary_accuracy: 0.8347 - val_loss: 0.4593 - val_binary_accuracy: 0.8097\n",
      "Epoch 224/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.4009 - binary_accuracy: 0.8363 - val_loss: 0.4588 - val_binary_accuracy: 0.8097\n",
      "Epoch 225/500\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3873 - binary_accuracy: 0.8435 - val_loss: 0.4572 - val_binary_accuracy: 0.8097\n",
      "Epoch 226/500\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3966 - binary_accuracy: 0.8266 - val_loss: 0.4536 - val_binary_accuracy: 0.8097\n",
      "Epoch 227/500\n",
      "623/623 [==============================] - 0s 87us/step - loss: 0.3943 - binary_accuracy: 0.8483 - val_loss: 0.4514 - val_binary_accuracy: 0.8153\n",
      "Epoch 228/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3963 - binary_accuracy: 0.8339 - val_loss: 0.4509 - val_binary_accuracy: 0.8153\n",
      "Epoch 229/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3942 - binary_accuracy: 0.8331 - val_loss: 0.4515 - val_binary_accuracy: 0.8134\n",
      "Epoch 230/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.3820 - binary_accuracy: 0.8347 - val_loss: 0.4532 - val_binary_accuracy: 0.8134\n",
      "Epoch 231/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3854 - binary_accuracy: 0.8363 - val_loss: 0.4569 - val_binary_accuracy: 0.8097\n",
      "Epoch 232/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.3836 - binary_accuracy: 0.8291 - val_loss: 0.4600 - val_binary_accuracy: 0.8078\n",
      "Epoch 233/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.3884 - binary_accuracy: 0.8491 - val_loss: 0.4588 - val_binary_accuracy: 0.8097\n",
      "Epoch 234/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3918 - binary_accuracy: 0.8323 - val_loss: 0.4553 - val_binary_accuracy: 0.8097\n",
      "Epoch 235/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.4049 - binary_accuracy: 0.8299 - val_loss: 0.4517 - val_binary_accuracy: 0.8134\n",
      "Epoch 236/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.4026 - binary_accuracy: 0.8323 - val_loss: 0.4492 - val_binary_accuracy: 0.8134\n",
      "Epoch 237/500\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3978 - binary_accuracy: 0.8242 - val_loss: 0.4493 - val_binary_accuracy: 0.8190\n",
      "Epoch 238/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.3836 - binary_accuracy: 0.8395 - val_loss: 0.4506 - val_binary_accuracy: 0.8172\n",
      "Epoch 239/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3995 - binary_accuracy: 0.8371 - val_loss: 0.4523 - val_binary_accuracy: 0.8116\n",
      "Epoch 240/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.3969 - binary_accuracy: 0.8307 - val_loss: 0.4554 - val_binary_accuracy: 0.8060\n",
      "Epoch 241/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3811 - binary_accuracy: 0.8387 - val_loss: 0.4578 - val_binary_accuracy: 0.8060\n",
      "Epoch 242/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.3853 - binary_accuracy: 0.8371 - val_loss: 0.4576 - val_binary_accuracy: 0.8060\n",
      "Epoch 243/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.4013 - binary_accuracy: 0.8395 - val_loss: 0.4548 - val_binary_accuracy: 0.8116\n",
      "Epoch 244/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3841 - binary_accuracy: 0.8283 - val_loss: 0.4514 - val_binary_accuracy: 0.8172\n",
      "Epoch 245/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3949 - binary_accuracy: 0.8283 - val_loss: 0.4506 - val_binary_accuracy: 0.8134\n",
      "Epoch 246/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3814 - binary_accuracy: 0.8387 - val_loss: 0.4516 - val_binary_accuracy: 0.8172\n",
      "Epoch 247/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.3832 - binary_accuracy: 0.8419 - val_loss: 0.4539 - val_binary_accuracy: 0.8134\n",
      "Epoch 248/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3796 - binary_accuracy: 0.8467 - val_loss: 0.4571 - val_binary_accuracy: 0.8116\n",
      "Epoch 249/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3811 - binary_accuracy: 0.8499 - val_loss: 0.4590 - val_binary_accuracy: 0.8116\n",
      "Epoch 250/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3966 - binary_accuracy: 0.8331 - val_loss: 0.4583 - val_binary_accuracy: 0.8134\n",
      "Epoch 251/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3897 - binary_accuracy: 0.8226 - val_loss: 0.4560 - val_binary_accuracy: 0.8097\n",
      "Epoch 252/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3882 - binary_accuracy: 0.8291 - val_loss: 0.4532 - val_binary_accuracy: 0.8097\n",
      "Epoch 253/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3879 - binary_accuracy: 0.8331 - val_loss: 0.4520 - val_binary_accuracy: 0.8116\n",
      "Epoch 254/500\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.3991 - binary_accuracy: 0.8419 - val_loss: 0.4517 - val_binary_accuracy: 0.8116\n",
      "Epoch 255/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3797 - binary_accuracy: 0.8467 - val_loss: 0.4522 - val_binary_accuracy: 0.8134\n",
      "Epoch 256/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3819 - binary_accuracy: 0.8451 - val_loss: 0.4537 - val_binary_accuracy: 0.8097\n",
      "Epoch 257/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3892 - binary_accuracy: 0.8347 - val_loss: 0.4555 - val_binary_accuracy: 0.8097\n",
      "Epoch 258/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3739 - binary_accuracy: 0.8411 - val_loss: 0.4556 - val_binary_accuracy: 0.8097\n",
      "Epoch 259/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3901 - binary_accuracy: 0.8274 - val_loss: 0.4555 - val_binary_accuracy: 0.8097\n",
      "Epoch 260/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.3757 - binary_accuracy: 0.8435 - val_loss: 0.4543 - val_binary_accuracy: 0.8116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.3776 - binary_accuracy: 0.8307 - val_loss: 0.4539 - val_binary_accuracy: 0.8116\n",
      "Epoch 262/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3851 - binary_accuracy: 0.8419 - val_loss: 0.4530 - val_binary_accuracy: 0.8134\n",
      "Epoch 263/500\n",
      "623/623 [==============================] - 0s 83us/step - loss: 0.3922 - binary_accuracy: 0.8379 - val_loss: 0.4530 - val_binary_accuracy: 0.8134\n",
      "Epoch 264/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.3853 - binary_accuracy: 0.8371 - val_loss: 0.4536 - val_binary_accuracy: 0.8116\n",
      "Epoch 265/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3789 - binary_accuracy: 0.8355 - val_loss: 0.4555 - val_binary_accuracy: 0.8097\n",
      "Epoch 266/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3871 - binary_accuracy: 0.8299 - val_loss: 0.4556 - val_binary_accuracy: 0.8097\n",
      "Epoch 267/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.3741 - binary_accuracy: 0.8371 - val_loss: 0.4541 - val_binary_accuracy: 0.8060\n",
      "Epoch 268/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3619 - binary_accuracy: 0.8507 - val_loss: 0.4525 - val_binary_accuracy: 0.8097\n",
      "Epoch 269/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.3880 - binary_accuracy: 0.8435 - val_loss: 0.4518 - val_binary_accuracy: 0.8097\n",
      "Epoch 270/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3773 - binary_accuracy: 0.8379 - val_loss: 0.4517 - val_binary_accuracy: 0.8134\n",
      "Epoch 271/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.3768 - binary_accuracy: 0.8443 - val_loss: 0.4517 - val_binary_accuracy: 0.8134\n",
      "Epoch 272/500\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3774 - binary_accuracy: 0.8443 - val_loss: 0.4521 - val_binary_accuracy: 0.8134\n",
      "Epoch 273/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3822 - binary_accuracy: 0.8427 - val_loss: 0.4526 - val_binary_accuracy: 0.8097\n",
      "Epoch 274/500\n",
      "623/623 [==============================] - 0s 87us/step - loss: 0.3796 - binary_accuracy: 0.8411 - val_loss: 0.4541 - val_binary_accuracy: 0.8060\n",
      "Epoch 275/500\n",
      "623/623 [==============================] - 0s 92us/step - loss: 0.3834 - binary_accuracy: 0.8395 - val_loss: 0.4544 - val_binary_accuracy: 0.8060\n",
      "Epoch 276/500\n",
      "623/623 [==============================] - 0s 100us/step - loss: 0.3789 - binary_accuracy: 0.8435 - val_loss: 0.4545 - val_binary_accuracy: 0.8060\n",
      "Epoch 277/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.3758 - binary_accuracy: 0.8387 - val_loss: 0.4538 - val_binary_accuracy: 0.8097\n",
      "Epoch 278/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3854 - binary_accuracy: 0.8363 - val_loss: 0.4523 - val_binary_accuracy: 0.8134\n",
      "Epoch 279/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.3727 - binary_accuracy: 0.8403 - val_loss: 0.4526 - val_binary_accuracy: 0.8134\n",
      "Epoch 280/500\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3730 - binary_accuracy: 0.8491 - val_loss: 0.4529 - val_binary_accuracy: 0.8097\n",
      "Epoch 281/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3725 - binary_accuracy: 0.8499 - val_loss: 0.4543 - val_binary_accuracy: 0.8116\n",
      "Epoch 282/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3902 - binary_accuracy: 0.8379 - val_loss: 0.4545 - val_binary_accuracy: 0.8097\n",
      "Epoch 283/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3666 - binary_accuracy: 0.8483 - val_loss: 0.4546 - val_binary_accuracy: 0.8097\n",
      "Epoch 284/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.3591 - binary_accuracy: 0.8459 - val_loss: 0.4547 - val_binary_accuracy: 0.8097\n",
      "Epoch 285/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3688 - binary_accuracy: 0.8411 - val_loss: 0.4557 - val_binary_accuracy: 0.8116\n",
      "Epoch 286/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.3709 - binary_accuracy: 0.8435 - val_loss: 0.4555 - val_binary_accuracy: 0.8134\n",
      "Epoch 287/500\n",
      "623/623 [==============================] - 0s 92us/step - loss: 0.3666 - binary_accuracy: 0.8547 - val_loss: 0.4554 - val_binary_accuracy: 0.8134\n",
      "Epoch 288/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3832 - binary_accuracy: 0.8379 - val_loss: 0.4563 - val_binary_accuracy: 0.8116\n",
      "Epoch 289/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3722 - binary_accuracy: 0.8459 - val_loss: 0.4562 - val_binary_accuracy: 0.8116\n",
      "Epoch 290/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3852 - binary_accuracy: 0.8355 - val_loss: 0.4540 - val_binary_accuracy: 0.8134\n",
      "Epoch 291/500\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3652 - binary_accuracy: 0.8491 - val_loss: 0.4528 - val_binary_accuracy: 0.8134\n",
      "Epoch 292/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3748 - binary_accuracy: 0.8507 - val_loss: 0.4525 - val_binary_accuracy: 0.8097\n",
      "Epoch 293/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3761 - binary_accuracy: 0.8411 - val_loss: 0.4526 - val_binary_accuracy: 0.8097\n",
      "Epoch 294/500\n",
      "623/623 [==============================] - 0s 87us/step - loss: 0.3752 - binary_accuracy: 0.8363 - val_loss: 0.4531 - val_binary_accuracy: 0.8097\n",
      "Epoch 295/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.3849 - binary_accuracy: 0.8379 - val_loss: 0.4533 - val_binary_accuracy: 0.8060\n",
      "Epoch 296/500\n",
      "623/623 [==============================] - 0s 74us/step - loss: 0.3703 - binary_accuracy: 0.8491 - val_loss: 0.4515 - val_binary_accuracy: 0.8097\n",
      "Epoch 297/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.3713 - binary_accuracy: 0.8411 - val_loss: 0.4497 - val_binary_accuracy: 0.8153\n",
      "Epoch 298/500\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3688 - binary_accuracy: 0.8403 - val_loss: 0.4514 - val_binary_accuracy: 0.8078\n",
      "Epoch 299/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.3692 - binary_accuracy: 0.8411 - val_loss: 0.4530 - val_binary_accuracy: 0.8060\n",
      "Epoch 300/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3565 - binary_accuracy: 0.8427 - val_loss: 0.4553 - val_binary_accuracy: 0.8060\n",
      "Epoch 301/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.3843 - binary_accuracy: 0.8331 - val_loss: 0.4555 - val_binary_accuracy: 0.8060\n",
      "Epoch 302/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3745 - binary_accuracy: 0.8483 - val_loss: 0.4518 - val_binary_accuracy: 0.8078\n",
      "Epoch 303/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3641 - binary_accuracy: 0.8443 - val_loss: 0.4487 - val_binary_accuracy: 0.8209\n",
      "Epoch 304/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3636 - binary_accuracy: 0.8539 - val_loss: 0.4475 - val_binary_accuracy: 0.8209\n",
      "Epoch 305/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.3635 - binary_accuracy: 0.8411 - val_loss: 0.4480 - val_binary_accuracy: 0.8190\n",
      "Epoch 306/500\n",
      "623/623 [==============================] - 0s 53us/step - loss: 0.3712 - binary_accuracy: 0.8435 - val_loss: 0.4497 - val_binary_accuracy: 0.8172\n",
      "Epoch 307/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3602 - binary_accuracy: 0.8539 - val_loss: 0.4519 - val_binary_accuracy: 0.8153\n",
      "Epoch 308/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.3653 - binary_accuracy: 0.8483 - val_loss: 0.4528 - val_binary_accuracy: 0.8134\n",
      "Epoch 309/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.3637 - binary_accuracy: 0.8499 - val_loss: 0.4532 - val_binary_accuracy: 0.8116\n",
      "Epoch 310/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3605 - binary_accuracy: 0.8523 - val_loss: 0.4528 - val_binary_accuracy: 0.8116\n",
      "Epoch 311/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3640 - binary_accuracy: 0.8411 - val_loss: 0.4521 - val_binary_accuracy: 0.8116\n",
      "Epoch 312/500\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.3535 - binary_accuracy: 0.8451 - val_loss: 0.4522 - val_binary_accuracy: 0.8116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/500\n",
      "623/623 [==============================] - 0s 53us/step - loss: 0.3596 - binary_accuracy: 0.8435 - val_loss: 0.4558 - val_binary_accuracy: 0.8153\n",
      "Epoch 314/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3649 - binary_accuracy: 0.8499 - val_loss: 0.4585 - val_binary_accuracy: 0.8134\n",
      "Epoch 315/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.3566 - binary_accuracy: 0.8628 - val_loss: 0.4609 - val_binary_accuracy: 0.8097\n",
      "Epoch 316/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.3695 - binary_accuracy: 0.8459 - val_loss: 0.4597 - val_binary_accuracy: 0.8097\n",
      "Epoch 317/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3525 - binary_accuracy: 0.8467 - val_loss: 0.4561 - val_binary_accuracy: 0.8078\n",
      "Epoch 318/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.3724 - binary_accuracy: 0.8427 - val_loss: 0.4496 - val_binary_accuracy: 0.8153\n",
      "Epoch 319/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.3511 - binary_accuracy: 0.8475 - val_loss: 0.4447 - val_binary_accuracy: 0.8209\n",
      "Epoch 320/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3678 - binary_accuracy: 0.8387 - val_loss: 0.4433 - val_binary_accuracy: 0.8246\n",
      "Epoch 321/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3516 - binary_accuracy: 0.8539 - val_loss: 0.4451 - val_binary_accuracy: 0.8209\n",
      "Epoch 322/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.3679 - binary_accuracy: 0.8459 - val_loss: 0.4489 - val_binary_accuracy: 0.8190\n",
      "Epoch 323/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.3493 - binary_accuracy: 0.8636 - val_loss: 0.4552 - val_binary_accuracy: 0.8153\n",
      "Epoch 324/500\n",
      "623/623 [==============================] - 0s 81us/step - loss: 0.3630 - binary_accuracy: 0.8451 - val_loss: 0.4584 - val_binary_accuracy: 0.8153\n",
      "Epoch 325/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.3715 - binary_accuracy: 0.8395 - val_loss: 0.4549 - val_binary_accuracy: 0.8134\n",
      "Epoch 326/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.3540 - binary_accuracy: 0.8547 - val_loss: 0.4503 - val_binary_accuracy: 0.8190\n",
      "Epoch 327/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3651 - binary_accuracy: 0.8403 - val_loss: 0.4468 - val_binary_accuracy: 0.8209\n",
      "Epoch 328/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3589 - binary_accuracy: 0.8475 - val_loss: 0.4471 - val_binary_accuracy: 0.8209\n",
      "Epoch 329/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.3497 - binary_accuracy: 0.8507 - val_loss: 0.4498 - val_binary_accuracy: 0.8209\n",
      "Epoch 330/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.3496 - binary_accuracy: 0.8475 - val_loss: 0.4541 - val_binary_accuracy: 0.8172\n",
      "Epoch 331/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3608 - binary_accuracy: 0.8491 - val_loss: 0.4573 - val_binary_accuracy: 0.8190\n",
      "Epoch 332/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3569 - binary_accuracy: 0.8531 - val_loss: 0.4578 - val_binary_accuracy: 0.8172\n",
      "Epoch 333/500\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.3552 - binary_accuracy: 0.8579 - val_loss: 0.4560 - val_binary_accuracy: 0.8172\n",
      "Epoch 334/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3469 - binary_accuracy: 0.8531 - val_loss: 0.4543 - val_binary_accuracy: 0.8172\n",
      "Epoch 335/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3533 - binary_accuracy: 0.8563 - val_loss: 0.4546 - val_binary_accuracy: 0.8172\n",
      "Epoch 336/500\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.3419 - binary_accuracy: 0.8531 - val_loss: 0.4575 - val_binary_accuracy: 0.8172\n",
      "Epoch 337/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.3499 - binary_accuracy: 0.8531 - val_loss: 0.4598 - val_binary_accuracy: 0.8190\n",
      "Epoch 338/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.3536 - binary_accuracy: 0.8515 - val_loss: 0.4588 - val_binary_accuracy: 0.8190\n",
      "Epoch 339/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3556 - binary_accuracy: 0.8515 - val_loss: 0.4552 - val_binary_accuracy: 0.8172\n",
      "Epoch 340/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3550 - binary_accuracy: 0.8515 - val_loss: 0.4504 - val_binary_accuracy: 0.8209\n",
      "Epoch 341/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.3513 - binary_accuracy: 0.8499 - val_loss: 0.4469 - val_binary_accuracy: 0.8209\n",
      "Epoch 342/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3578 - binary_accuracy: 0.8443 - val_loss: 0.4469 - val_binary_accuracy: 0.8228\n",
      "Epoch 343/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3568 - binary_accuracy: 0.8507 - val_loss: 0.4494 - val_binary_accuracy: 0.8209\n",
      "Epoch 344/500\n",
      "623/623 [==============================] - 0s 84us/step - loss: 0.3485 - binary_accuracy: 0.8515 - val_loss: 0.4519 - val_binary_accuracy: 0.8172\n",
      "Epoch 345/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3453 - binary_accuracy: 0.8499 - val_loss: 0.4537 - val_binary_accuracy: 0.8209\n",
      "Epoch 346/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.3479 - binary_accuracy: 0.8435 - val_loss: 0.4543 - val_binary_accuracy: 0.8190\n",
      "Epoch 347/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.3482 - binary_accuracy: 0.8459 - val_loss: 0.4538 - val_binary_accuracy: 0.8209\n",
      "Epoch 348/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3462 - binary_accuracy: 0.8483 - val_loss: 0.4529 - val_binary_accuracy: 0.8209\n",
      "Epoch 349/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.3398 - binary_accuracy: 0.8571 - val_loss: 0.4514 - val_binary_accuracy: 0.8209\n",
      "Epoch 350/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.3563 - binary_accuracy: 0.8475 - val_loss: 0.4511 - val_binary_accuracy: 0.8209\n",
      "Epoch 351/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.3307 - binary_accuracy: 0.8579 - val_loss: 0.4543 - val_binary_accuracy: 0.8190\n",
      "Epoch 352/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3358 - binary_accuracy: 0.8708 - val_loss: 0.4589 - val_binary_accuracy: 0.8228\n",
      "Epoch 353/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.3564 - binary_accuracy: 0.8507 - val_loss: 0.4588 - val_binary_accuracy: 0.8209\n",
      "Epoch 354/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3343 - binary_accuracy: 0.8539 - val_loss: 0.4578 - val_binary_accuracy: 0.8209\n",
      "Epoch 355/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3369 - binary_accuracy: 0.8571 - val_loss: 0.4561 - val_binary_accuracy: 0.8209\n",
      "Epoch 356/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3424 - binary_accuracy: 0.8604 - val_loss: 0.4504 - val_binary_accuracy: 0.8190\n",
      "Epoch 357/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.3369 - binary_accuracy: 0.8587 - val_loss: 0.4451 - val_binary_accuracy: 0.8246\n",
      "Epoch 358/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3362 - binary_accuracy: 0.8579 - val_loss: 0.4452 - val_binary_accuracy: 0.8246\n",
      "Epoch 359/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3396 - binary_accuracy: 0.8571 - val_loss: 0.4516 - val_binary_accuracy: 0.8246\n",
      "Epoch 360/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3484 - binary_accuracy: 0.8419 - val_loss: 0.4567 - val_binary_accuracy: 0.8265\n",
      "Epoch 361/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3316 - binary_accuracy: 0.8596 - val_loss: 0.4638 - val_binary_accuracy: 0.8209\n",
      "Epoch 362/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3385 - binary_accuracy: 0.8563 - val_loss: 0.4643 - val_binary_accuracy: 0.8190\n",
      "Epoch 363/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.3272 - binary_accuracy: 0.8579 - val_loss: 0.4602 - val_binary_accuracy: 0.8228\n",
      "Epoch 364/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3521 - binary_accuracy: 0.8555 - val_loss: 0.4558 - val_binary_accuracy: 0.8340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.3327 - binary_accuracy: 0.8628 - val_loss: 0.4530 - val_binary_accuracy: 0.8340\n",
      "Epoch 366/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3425 - binary_accuracy: 0.8451 - val_loss: 0.4557 - val_binary_accuracy: 0.8377\n",
      "Epoch 367/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3390 - binary_accuracy: 0.8547 - val_loss: 0.4586 - val_binary_accuracy: 0.8358\n",
      "Epoch 368/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3341 - binary_accuracy: 0.8620 - val_loss: 0.4597 - val_binary_accuracy: 0.8321\n",
      "Epoch 369/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.3254 - binary_accuracy: 0.8652 - val_loss: 0.4598 - val_binary_accuracy: 0.8321\n",
      "Epoch 370/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.3412 - binary_accuracy: 0.8547 - val_loss: 0.4621 - val_binary_accuracy: 0.8284\n",
      "Epoch 371/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.3187 - binary_accuracy: 0.8636 - val_loss: 0.4650 - val_binary_accuracy: 0.8302\n",
      "Epoch 372/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3386 - binary_accuracy: 0.8604 - val_loss: 0.4675 - val_binary_accuracy: 0.8265\n",
      "Epoch 373/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.3330 - binary_accuracy: 0.8636 - val_loss: 0.4729 - val_binary_accuracy: 0.8209\n",
      "Epoch 374/500\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3324 - binary_accuracy: 0.8547 - val_loss: 0.4752 - val_binary_accuracy: 0.8190\n",
      "Epoch 375/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3332 - binary_accuracy: 0.8684 - val_loss: 0.4752 - val_binary_accuracy: 0.8209\n",
      "Epoch 376/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3278 - binary_accuracy: 0.8531 - val_loss: 0.4747 - val_binary_accuracy: 0.8209\n",
      "Epoch 377/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.3365 - binary_accuracy: 0.8579 - val_loss: 0.4700 - val_binary_accuracy: 0.8265\n",
      "Epoch 378/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3330 - binary_accuracy: 0.8636 - val_loss: 0.4640 - val_binary_accuracy: 0.8321\n",
      "Epoch 379/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3316 - binary_accuracy: 0.8612 - val_loss: 0.4591 - val_binary_accuracy: 0.8377\n",
      "Epoch 380/500\n",
      "623/623 [==============================] - 0s 79us/step - loss: 0.3212 - binary_accuracy: 0.8644 - val_loss: 0.4607 - val_binary_accuracy: 0.8414\n",
      "Epoch 381/500\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.3194 - binary_accuracy: 0.8692 - val_loss: 0.4684 - val_binary_accuracy: 0.8265\n",
      "Epoch 382/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3246 - binary_accuracy: 0.8555 - val_loss: 0.4730 - val_binary_accuracy: 0.8209\n",
      "Epoch 383/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.3100 - binary_accuracy: 0.8660 - val_loss: 0.4759 - val_binary_accuracy: 0.8209\n",
      "Epoch 384/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3214 - binary_accuracy: 0.8628 - val_loss: 0.4772 - val_binary_accuracy: 0.8209\n",
      "Epoch 385/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3302 - binary_accuracy: 0.8612 - val_loss: 0.4734 - val_binary_accuracy: 0.8265\n",
      "Epoch 386/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3185 - binary_accuracy: 0.8563 - val_loss: 0.4704 - val_binary_accuracy: 0.8302\n",
      "Epoch 387/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.3247 - binary_accuracy: 0.8692 - val_loss: 0.4669 - val_binary_accuracy: 0.8358\n",
      "Epoch 388/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3284 - binary_accuracy: 0.8596 - val_loss: 0.4621 - val_binary_accuracy: 0.8396\n",
      "Epoch 389/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3179 - binary_accuracy: 0.8644 - val_loss: 0.4612 - val_binary_accuracy: 0.8396\n",
      "Epoch 390/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.3247 - binary_accuracy: 0.8628 - val_loss: 0.4590 - val_binary_accuracy: 0.8377\n",
      "Epoch 391/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3214 - binary_accuracy: 0.8620 - val_loss: 0.4577 - val_binary_accuracy: 0.8358\n",
      "Epoch 392/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.3222 - binary_accuracy: 0.8660 - val_loss: 0.4590 - val_binary_accuracy: 0.8321\n",
      "Epoch 393/500\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.3173 - binary_accuracy: 0.8587 - val_loss: 0.4600 - val_binary_accuracy: 0.8321\n",
      "Epoch 394/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3289 - binary_accuracy: 0.8644 - val_loss: 0.4606 - val_binary_accuracy: 0.8321\n",
      "Epoch 395/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3178 - binary_accuracy: 0.8668 - val_loss: 0.4638 - val_binary_accuracy: 0.8284\n",
      "Epoch 396/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3015 - binary_accuracy: 0.8740 - val_loss: 0.4652 - val_binary_accuracy: 0.8284\n",
      "Epoch 397/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.3141 - binary_accuracy: 0.8772 - val_loss: 0.4657 - val_binary_accuracy: 0.8284\n",
      "Epoch 398/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3204 - binary_accuracy: 0.8604 - val_loss: 0.4702 - val_binary_accuracy: 0.8246\n",
      "Epoch 399/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3071 - binary_accuracy: 0.8612 - val_loss: 0.4714 - val_binary_accuracy: 0.8246\n",
      "Epoch 400/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3153 - binary_accuracy: 0.8732 - val_loss: 0.4670 - val_binary_accuracy: 0.8321\n",
      "Epoch 401/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3127 - binary_accuracy: 0.8596 - val_loss: 0.4633 - val_binary_accuracy: 0.8358\n",
      "Epoch 402/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.3173 - binary_accuracy: 0.8571 - val_loss: 0.4618 - val_binary_accuracy: 0.8358\n",
      "Epoch 403/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3125 - binary_accuracy: 0.8684 - val_loss: 0.4631 - val_binary_accuracy: 0.8340\n",
      "Epoch 404/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.3109 - binary_accuracy: 0.8764 - val_loss: 0.4682 - val_binary_accuracy: 0.8284\n",
      "Epoch 405/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.3060 - binary_accuracy: 0.8764 - val_loss: 0.4722 - val_binary_accuracy: 0.8228\n",
      "Epoch 406/500\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.3090 - binary_accuracy: 0.8596 - val_loss: 0.4751 - val_binary_accuracy: 0.8209\n",
      "Epoch 407/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3134 - binary_accuracy: 0.8644 - val_loss: 0.4761 - val_binary_accuracy: 0.8209\n",
      "Epoch 408/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2944 - binary_accuracy: 0.8772 - val_loss: 0.4736 - val_binary_accuracy: 0.8228\n",
      "Epoch 409/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.2924 - binary_accuracy: 0.8740 - val_loss: 0.4714 - val_binary_accuracy: 0.8358\n",
      "Epoch 410/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.3064 - binary_accuracy: 0.8732 - val_loss: 0.4730 - val_binary_accuracy: 0.8321\n",
      "Epoch 411/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.3040 - binary_accuracy: 0.8772 - val_loss: 0.4775 - val_binary_accuracy: 0.8358\n",
      "Epoch 412/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.3074 - binary_accuracy: 0.8660 - val_loss: 0.4824 - val_binary_accuracy: 0.8302\n",
      "Epoch 413/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.3164 - binary_accuracy: 0.8684 - val_loss: 0.4835 - val_binary_accuracy: 0.8284\n",
      "Epoch 414/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.3094 - binary_accuracy: 0.8716 - val_loss: 0.4812 - val_binary_accuracy: 0.8302\n",
      "Epoch 415/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.3224 - binary_accuracy: 0.8636 - val_loss: 0.4819 - val_binary_accuracy: 0.8246\n",
      "Epoch 416/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.2920 - binary_accuracy: 0.8764 - val_loss: 0.4810 - val_binary_accuracy: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/500\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.3043 - binary_accuracy: 0.8732 - val_loss: 0.4787 - val_binary_accuracy: 0.8228\n",
      "Epoch 418/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.3024 - binary_accuracy: 0.8788 - val_loss: 0.4735 - val_binary_accuracy: 0.8246\n",
      "Epoch 419/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2956 - binary_accuracy: 0.8708 - val_loss: 0.4701 - val_binary_accuracy: 0.8358\n",
      "Epoch 420/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.2915 - binary_accuracy: 0.8780 - val_loss: 0.4723 - val_binary_accuracy: 0.8358\n",
      "Epoch 421/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2947 - binary_accuracy: 0.8732 - val_loss: 0.4752 - val_binary_accuracy: 0.8340\n",
      "Epoch 422/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.3042 - binary_accuracy: 0.8748 - val_loss: 0.4745 - val_binary_accuracy: 0.8321\n",
      "Epoch 423/500\n",
      "623/623 [==============================] - 0s 90us/step - loss: 0.2941 - binary_accuracy: 0.8804 - val_loss: 0.4751 - val_binary_accuracy: 0.8321\n",
      "Epoch 424/500\n",
      "623/623 [==============================] - 0s 93us/step - loss: 0.2958 - binary_accuracy: 0.8812 - val_loss: 0.4755 - val_binary_accuracy: 0.8321\n",
      "Epoch 425/500\n",
      "623/623 [==============================] - 0s 81us/step - loss: 0.3063 - binary_accuracy: 0.8724 - val_loss: 0.4753 - val_binary_accuracy: 0.8321\n",
      "Epoch 426/500\n",
      "623/623 [==============================] - 0s 78us/step - loss: 0.3167 - binary_accuracy: 0.8660 - val_loss: 0.4717 - val_binary_accuracy: 0.8284\n",
      "Epoch 427/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.3000 - binary_accuracy: 0.8732 - val_loss: 0.4708 - val_binary_accuracy: 0.8302\n",
      "Epoch 428/500\n",
      "623/623 [==============================] - 0s 73us/step - loss: 0.2805 - binary_accuracy: 0.8836 - val_loss: 0.4759 - val_binary_accuracy: 0.8246\n",
      "Epoch 429/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.2853 - binary_accuracy: 0.8772 - val_loss: 0.4838 - val_binary_accuracy: 0.8246\n",
      "Epoch 430/500\n",
      "623/623 [==============================] - 0s 86us/step - loss: 0.2879 - binary_accuracy: 0.8844 - val_loss: 0.4926 - val_binary_accuracy: 0.8209\n",
      "Epoch 431/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.3136 - binary_accuracy: 0.8692 - val_loss: 0.4901 - val_binary_accuracy: 0.8246\n",
      "Epoch 432/500\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.2896 - binary_accuracy: 0.8796 - val_loss: 0.4853 - val_binary_accuracy: 0.8284\n",
      "Epoch 433/500\n",
      "623/623 [==============================] - 0s 82us/step - loss: 0.2861 - binary_accuracy: 0.8909 - val_loss: 0.4824 - val_binary_accuracy: 0.8340\n",
      "Epoch 434/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.2859 - binary_accuracy: 0.8860 - val_loss: 0.4824 - val_binary_accuracy: 0.8321\n",
      "Epoch 435/500\n",
      "623/623 [==============================] - 0s 70us/step - loss: 0.2900 - binary_accuracy: 0.8860 - val_loss: 0.4861 - val_binary_accuracy: 0.8302\n",
      "Epoch 436/500\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.2791 - binary_accuracy: 0.8820 - val_loss: 0.4918 - val_binary_accuracy: 0.8246\n",
      "Epoch 437/500\n",
      "623/623 [==============================] - 0s 52us/step - loss: 0.2750 - binary_accuracy: 0.8860 - val_loss: 0.4976 - val_binary_accuracy: 0.8228\n",
      "Epoch 438/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.2889 - binary_accuracy: 0.8860 - val_loss: 0.4996 - val_binary_accuracy: 0.8246\n",
      "Epoch 439/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.2837 - binary_accuracy: 0.8796 - val_loss: 0.5012 - val_binary_accuracy: 0.8284\n",
      "Epoch 440/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.2927 - binary_accuracy: 0.8684 - val_loss: 0.5015 - val_binary_accuracy: 0.8358\n",
      "Epoch 441/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.2763 - binary_accuracy: 0.8772 - val_loss: 0.5054 - val_binary_accuracy: 0.8321\n",
      "Epoch 442/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.2813 - binary_accuracy: 0.8748 - val_loss: 0.5099 - val_binary_accuracy: 0.8246\n",
      "Epoch 443/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.2695 - binary_accuracy: 0.8812 - val_loss: 0.5125 - val_binary_accuracy: 0.8209\n",
      "Epoch 444/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.2858 - binary_accuracy: 0.8772 - val_loss: 0.5112 - val_binary_accuracy: 0.8209\n",
      "Epoch 445/500\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.2854 - binary_accuracy: 0.8917 - val_loss: 0.5044 - val_binary_accuracy: 0.8228\n",
      "Epoch 446/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.2800 - binary_accuracy: 0.8764 - val_loss: 0.5023 - val_binary_accuracy: 0.8284\n",
      "Epoch 447/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.2713 - binary_accuracy: 0.8900 - val_loss: 0.5021 - val_binary_accuracy: 0.8209\n",
      "Epoch 448/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.2551 - binary_accuracy: 0.8892 - val_loss: 0.5068 - val_binary_accuracy: 0.8172\n",
      "Epoch 449/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.2807 - binary_accuracy: 0.8796 - val_loss: 0.5140 - val_binary_accuracy: 0.8153\n",
      "Epoch 450/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2850 - binary_accuracy: 0.8796 - val_loss: 0.5201 - val_binary_accuracy: 0.8172\n",
      "Epoch 451/500\n",
      "623/623 [==============================] - 0s 50us/step - loss: 0.2659 - binary_accuracy: 0.8892 - val_loss: 0.5254 - val_binary_accuracy: 0.8172\n",
      "Epoch 452/500\n",
      "623/623 [==============================] - 0s 61us/step - loss: 0.2758 - binary_accuracy: 0.8860 - val_loss: 0.5216 - val_binary_accuracy: 0.8209\n",
      "Epoch 453/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.2747 - binary_accuracy: 0.8828 - val_loss: 0.5159 - val_binary_accuracy: 0.8246\n",
      "Epoch 454/500\n",
      "623/623 [==============================] - 0s 67us/step - loss: 0.2806 - binary_accuracy: 0.8780 - val_loss: 0.5162 - val_binary_accuracy: 0.8284\n",
      "Epoch 455/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.2703 - binary_accuracy: 0.8900 - val_loss: 0.5227 - val_binary_accuracy: 0.8321\n",
      "Epoch 456/500\n",
      "623/623 [==============================] - 0s 65us/step - loss: 0.2762 - binary_accuracy: 0.8812 - val_loss: 0.5262 - val_binary_accuracy: 0.8321\n",
      "Epoch 457/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2534 - binary_accuracy: 0.8917 - val_loss: 0.5322 - val_binary_accuracy: 0.8321\n",
      "Epoch 458/500\n",
      "623/623 [==============================] - 0s 49us/step - loss: 0.2583 - binary_accuracy: 0.8780 - val_loss: 0.5348 - val_binary_accuracy: 0.8284\n",
      "Epoch 459/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2833 - binary_accuracy: 0.8812 - val_loss: 0.5454 - val_binary_accuracy: 0.8209\n",
      "Epoch 460/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.2654 - binary_accuracy: 0.8860 - val_loss: 0.5456 - val_binary_accuracy: 0.8209\n",
      "Epoch 461/500\n",
      "623/623 [==============================] - 0s 55us/step - loss: 0.2634 - binary_accuracy: 0.8900 - val_loss: 0.5403 - val_binary_accuracy: 0.8302\n",
      "Epoch 462/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.2808 - binary_accuracy: 0.8836 - val_loss: 0.5305 - val_binary_accuracy: 0.8358\n",
      "Epoch 463/500\n",
      "623/623 [==============================] - 0s 57us/step - loss: 0.2669 - binary_accuracy: 0.8836 - val_loss: 0.5235 - val_binary_accuracy: 0.8396\n",
      "Epoch 464/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.2756 - binary_accuracy: 0.8949 - val_loss: 0.5231 - val_binary_accuracy: 0.8377\n",
      "Epoch 465/500\n",
      "623/623 [==============================] - 0s 53us/step - loss: 0.2605 - binary_accuracy: 0.8852 - val_loss: 0.5250 - val_binary_accuracy: 0.8284\n",
      "Epoch 466/500\n",
      "623/623 [==============================] - 0s 53us/step - loss: 0.2726 - binary_accuracy: 0.8804 - val_loss: 0.5270 - val_binary_accuracy: 0.8340\n",
      "Epoch 467/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.2707 - binary_accuracy: 0.8925 - val_loss: 0.5333 - val_binary_accuracy: 0.8358\n",
      "Epoch 468/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.2722 - binary_accuracy: 0.8965 - val_loss: 0.5382 - val_binary_accuracy: 0.8358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.2488 - binary_accuracy: 0.8909 - val_loss: 0.5463 - val_binary_accuracy: 0.8321\n",
      "Epoch 470/500\n",
      "623/623 [==============================] - 0s 56us/step - loss: 0.2511 - binary_accuracy: 0.8965 - val_loss: 0.5521 - val_binary_accuracy: 0.8284\n",
      "Epoch 471/500\n",
      "623/623 [==============================] - 0s 59us/step - loss: 0.2510 - binary_accuracy: 0.8957 - val_loss: 0.5511 - val_binary_accuracy: 0.8246\n",
      "Epoch 472/500\n",
      "623/623 [==============================] - 0s 80us/step - loss: 0.2754 - binary_accuracy: 0.8764 - val_loss: 0.5416 - val_binary_accuracy: 0.8246\n",
      "Epoch 473/500\n",
      "623/623 [==============================] - 0s 85us/step - loss: 0.2523 - binary_accuracy: 0.8997 - val_loss: 0.5311 - val_binary_accuracy: 0.8284\n",
      "Epoch 474/500\n",
      "623/623 [==============================] - 0s 76us/step - loss: 0.2630 - binary_accuracy: 0.8957 - val_loss: 0.5185 - val_binary_accuracy: 0.8451\n",
      "Epoch 475/500\n",
      "623/623 [==============================] - 0s 75us/step - loss: 0.2619 - binary_accuracy: 0.8925 - val_loss: 0.5104 - val_binary_accuracy: 0.8489\n",
      "Epoch 476/500\n",
      "623/623 [==============================] - 0s 100us/step - loss: 0.2711 - binary_accuracy: 0.8965 - val_loss: 0.5118 - val_binary_accuracy: 0.8507\n",
      "Epoch 477/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.2655 - binary_accuracy: 0.8884 - val_loss: 0.5176 - val_binary_accuracy: 0.8507\n",
      "Epoch 478/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.2807 - binary_accuracy: 0.8780 - val_loss: 0.5347 - val_binary_accuracy: 0.8284\n",
      "Epoch 479/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.2573 - binary_accuracy: 0.8933 - val_loss: 0.5521 - val_binary_accuracy: 0.8153\n",
      "Epoch 480/500\n",
      "623/623 [==============================] - 0s 72us/step - loss: 0.2568 - binary_accuracy: 0.8933 - val_loss: 0.5674 - val_binary_accuracy: 0.8116\n",
      "Epoch 481/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.2494 - binary_accuracy: 0.8900 - val_loss: 0.5636 - val_binary_accuracy: 0.8228\n",
      "Epoch 482/500\n",
      "623/623 [==============================] - 0s 71us/step - loss: 0.2538 - binary_accuracy: 0.8933 - val_loss: 0.5559 - val_binary_accuracy: 0.8265\n",
      "Epoch 483/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.2438 - binary_accuracy: 0.8949 - val_loss: 0.5480 - val_binary_accuracy: 0.8340\n",
      "Epoch 484/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.2481 - binary_accuracy: 0.9005 - val_loss: 0.5406 - val_binary_accuracy: 0.8433\n",
      "Epoch 485/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.2526 - binary_accuracy: 0.8965 - val_loss: 0.5413 - val_binary_accuracy: 0.8284\n",
      "Epoch 486/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.2489 - binary_accuracy: 0.8949 - val_loss: 0.5439 - val_binary_accuracy: 0.8153\n",
      "Epoch 487/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.2480 - binary_accuracy: 0.8941 - val_loss: 0.5459 - val_binary_accuracy: 0.8134\n",
      "Epoch 488/500\n",
      "623/623 [==============================] - 0s 64us/step - loss: 0.2443 - binary_accuracy: 0.8973 - val_loss: 0.5453 - val_binary_accuracy: 0.8190\n",
      "Epoch 489/500\n",
      "623/623 [==============================] - 0s 62us/step - loss: 0.2458 - binary_accuracy: 0.8949 - val_loss: 0.5453 - val_binary_accuracy: 0.8340\n",
      "Epoch 490/500\n",
      "623/623 [==============================] - 0s 68us/step - loss: 0.2542 - binary_accuracy: 0.8965 - val_loss: 0.5458 - val_binary_accuracy: 0.8377\n",
      "Epoch 491/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.2645 - binary_accuracy: 0.8884 - val_loss: 0.5472 - val_binary_accuracy: 0.8340\n",
      "Epoch 492/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2533 - binary_accuracy: 0.8949 - val_loss: 0.5493 - val_binary_accuracy: 0.8358\n",
      "Epoch 493/500\n",
      "623/623 [==============================] - 0s 69us/step - loss: 0.2511 - binary_accuracy: 0.8933 - val_loss: 0.5614 - val_binary_accuracy: 0.8060\n",
      "Epoch 494/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2638 - binary_accuracy: 0.8900 - val_loss: 0.5667 - val_binary_accuracy: 0.8097\n",
      "Epoch 495/500\n",
      "623/623 [==============================] - 0s 63us/step - loss: 0.2495 - binary_accuracy: 0.8997 - val_loss: 0.5655 - val_binary_accuracy: 0.8228\n",
      "Epoch 496/500\n",
      "623/623 [==============================] - 0s 77us/step - loss: 0.2525 - binary_accuracy: 0.9053 - val_loss: 0.5593 - val_binary_accuracy: 0.8451\n",
      "Epoch 497/500\n",
      "623/623 [==============================] - 0s 60us/step - loss: 0.2366 - binary_accuracy: 0.8997 - val_loss: 0.5585 - val_binary_accuracy: 0.8582\n",
      "Epoch 498/500\n",
      "623/623 [==============================] - 0s 66us/step - loss: 0.2538 - binary_accuracy: 0.8884 - val_loss: 0.5552 - val_binary_accuracy: 0.8582\n",
      "Epoch 499/500\n",
      "623/623 [==============================] - 0s 58us/step - loss: 0.2423 - binary_accuracy: 0.9037 - val_loss: 0.5562 - val_binary_accuracy: 0.8433\n",
      "Epoch 500/500\n",
      "623/623 [==============================] - 0s 54us/step - loss: 0.2265 - binary_accuracy: 0.9021 - val_loss: 0.5656 - val_binary_accuracy: 0.8284\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.as_matrix()\n",
    "y_train = np_utils.to_categorical(y,classes)\n",
    "# kfold = StratifiedKFold(random_state=42)\n",
    "# for i,(train_idx,valid_idx) in enumerate(kfold.split(df_train,y)):\n",
    "#     X_train, y_train = df_train.iloc[train_idx],y.iloc[train_idx]\n",
    "#     X_valid, y_valid = df_train.iloc[valid_idx],y.iloc[valid_idx]\n",
    "    \n",
    "# X_train = X_train.as_matrix()\n",
    "# X_valid = X_valid.as_matrix()\n",
    "# y_train = np_utils.to_categorical(y[train_idx],classes)\n",
    "# y_valid = np_utils.to_categorical(y[valid_idx],classes)\n",
    "history = model.fit(X_train,y_train,batch_size=batch_size,epochs=epochs,verbose=verbose,validation_split=validation_split)\n",
    "# score = model.evaluate(X_valid,y_valid,verbose=verbose)\n",
    "# print(score)\n",
    "#     print('Test Score '.format(score[0]))\n",
    "#     print('Test Accuracy '.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gs['Survived'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_time = strftime('%Y-%m-%d-%H-%M-%S')\n",
    "df_gs.to_csv(f'My_ouptuts/output{curr_time}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    240\n",
       "1    178\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gs['Survived'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
